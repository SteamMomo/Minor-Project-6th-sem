{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Dataset as a pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AYUSH\\AppData\\Local\\Temp\\ipykernel_16944\\809371201.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dataset = imdb.append(ques, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "imdb = pd.read_csv(\"E:/Momo/Datasets/imdbreviews/IMDB Dataset.csv\")\n",
    "ques = pd.read_csv(\"E:/Momo/Datasets/questions/train.csv\")\n",
    "\n",
    "ques = ques.head(25000)\n",
    "ques[\"sentiment\"] = [\"question\"]*25000\n",
    "ques = ques.drop([\"context\", \"id\", \"title\", \"answers\"], axis= 1)\n",
    "ques.columns = [\"review\", \"sentiment\"]\n",
    "\n",
    "dataset = imdb.append(ques, ignore_index=True)\n",
    "\n",
    "# dataset[\"sentiment\"] = dataset[\"sentiment\"].replace(\"positive\",1).replace(\"negative\",0).replace(\"question\", 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing dataset\n",
    "\n",
    "Removing words and symbols that do not contain significant meaning.\n",
    "\n",
    "- Removing HTML tags\n",
    "- Removing URLs\n",
    "- Removing speacial characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_html_tags(text):\n",
    "    soup = BeautifulSoup(text,\"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_urls(text):\n",
    "    return re.sub(\"http\\S+\",\"\",text)\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    return re.sub(r'[^\\w\\s\\?]', '', text)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = remove_html_tags(text)\n",
    "    text = remove_urls(text)\n",
    "    text = remove_special_characters(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AYUSH\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset[\"review\"] = dataset[\"review\"].apply(clean_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting dataset into Training and Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000,) (30000,)\n"
     ]
    }
   ],
   "source": [
    "# Split features and labels\n",
    "X = dataset[\"review\"]\n",
    "y = dataset[\"sentiment\"]\n",
    "\n",
    "# Split train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4,random_state=0)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature vectors\n",
    "vectorizer = TfidfVectorizer(min_df = 5,\n",
    "                             max_df = 0.8,\n",
    "                             sublinear_tf = True,\n",
    "                             use_idf = True)\n",
    "train_vectors = vectorizer.fit_transform(X_train)\n",
    "test_vectors = vectorizer.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1244.436655s; Prediction time: 802.145438s\n"
     ]
    }
   ],
   "source": [
    "# Perform classification with SVM, kernel=linear\n",
    "classifier_linear = svm.SVC(kernel='linear')\n",
    "t0 = time.time()\n",
    "classifier_linear.fit(train_vectors, y_train)\n",
    "t1 = time.time()\n",
    "prediction_linear = classifier_linear.predict(test_vectors)\n",
    "t2 = time.time()\n",
    "time_linear_train = t1-t0\n",
    "time_linear_predict = t2-t1\n",
    "# results\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_linear_train, time_linear_predict))\n",
    "report = classification_report(y_test, prediction_linear, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'negative': {'precision': 0.9053930992613579, 'recall': 0.8834040872741633, 'f1-score': 0.8942634419348392, 'support': 10129}, 'positive': {'precision': 0.883325037332006, 'recall': 0.9035641547861507, 'f1-score': 0.893329977347093, 'support': 9820}, 'question': {'precision': 0.9979150119142176, 'recall': 1.0, 'f1-score': 0.9989564180291209, 'support': 10051}, 'accuracy': 0.9290666666666667, 'macro avg': {'precision': 0.9288777161691938, 'recall': 0.9289894140201046, 'f1-score': 0.928849945770351, 'support': 30000}, 'weighted avg': {'precision': 0.9291674117922798, 'recall': 0.9290666666666667, 'f1-score': 0.9290335246172379, 'support': 30000}}\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative']\n"
     ]
    }
   ],
   "source": [
    "classes = [\"negative\", \"positive\", \"question\"]\n",
    "review = \"this isnt accurate, i dont like it\"\n",
    "review_vector = vectorizer.transform([review]) # vectorizing\n",
    "print(classifier_linear.predict(review_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8230e6ed6797c94c2c15ffe42da92699550ae69d87667e3400b5be1b48ce7bc2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
